{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функции для тестового задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os import walk\n",
    "import datetime\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime, date\n",
    "\n",
    "import csv\n",
    "\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "import branca\n",
    "import branca.colormap as cm\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Графики\n",
    "`show_chart` отображает изменение координат широты и долготы по времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_chart(fig, data_a, data_b ):\n",
    "    \"\"\"\n",
    "    The function draws 2 chatrs: msisdn lattitude on time and msisdn longitude on time\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    data_a_copy = data_a\n",
    "    data_b_copy = data_b\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    feature = 'long'\n",
    "    plt.scatter(data_a_copy['datetime'], data_a_copy[feature], alpha = .5, c = 'blue')\n",
    "    plt.plot(data_a_copy['datetime'], data_a_copy[feature+'_max'],'-o',alpha = .3, color='blue')\n",
    "    plt.plot(data_a_copy['datetime'], data_a_copy[feature+'_min'],'-o',alpha = .3, color='blue')\n",
    "    plt.scatter(data_b_copy['datetime'], data_b_copy[feature], alpha = .5, c = 'red')\n",
    "    plt.plot(data_b_copy['datetime'], data_b_copy[feature+'_max'],'-o',alpha = .3, color='red')\n",
    "    plt.plot(data_b_copy['datetime'], data_b_copy[feature+'_min'],'-o',alpha = .3, color='red')\n",
    "    plt.xlim(pd.concat([data_a,data_b])['datetime'].min(), pd.concat([data_a,data_b])['datetime'].max())\n",
    "    plt.xticks(rotation=70)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    feature = 'lat'\n",
    "    plt.scatter(data_a_copy['datetime'], data_a_copy[feature], alpha = .5, c = 'blue')\n",
    "    plt.plot(data_a_copy['datetime'], data_a_copy[feature+'_max'],'-o',alpha = .3, color='blue')\n",
    "    plt.plot(data_a_copy['datetime'], data_a_copy[feature+'_min'],'-o',alpha = .3, color='blue')\n",
    "    plt.scatter(data_b_copy['datetime'], data_b_copy[feature], alpha = .5, c = 'red')\n",
    "    plt.plot(data_b_copy['datetime'], data_b_copy[feature+'_max'],'-o',alpha = .3, color='red')\n",
    "    plt.plot(data_b_copy['datetime'], data_b_copy[feature+'_min'],'-o',alpha = .3, color='red')\n",
    "    plt.xlim(pd.concat([data_a,data_b])['datetime'].min(), pd.concat([data_a,data_b])['datetime'].max())\n",
    "    plt.xticks(rotation=70)\n",
    "    \n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`show_circles_on_map` отображает точки в которых был абонент на карте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_circles_on_map(m, data, latitude_column, longitude_column, color):\n",
    "    \"\"\"\n",
    "    The function draws map with circles on it.\n",
    "    The center of the map is the mean of coordinates passed in data.\n",
    "    \n",
    "    data: DataFrame that contains columns latitude_column and longitude_column\n",
    "    latitude_column: string, the name of column for latitude coordinates\n",
    "    longitude_column: string, the name of column for longitude coordinates\n",
    "    color: string, the color of circles to be drawn\n",
    "    \"\"\"\n",
    "\n",
    "    location = (data[latitude_column].mean(), data[longitude_column].mean())\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        folium.Circle(\n",
    "            radius=100,\n",
    "            location=(row[latitude_column], row[longitude_column]),\n",
    "            color=color,\n",
    "            fill_color=color,\n",
    "            fill=True,\n",
    "            fill_opacity = .5\n",
    "        ).add_to(m)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`haversine_array` определяет расстояние в метрах по координатам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_array(lat1, lng1, lat2, lng2):\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n",
    "    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка координат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BS_rectangle_coordinate` по координатам БС, максимальной дистанции приема и направлению и углу покрятия определяет координаты прямоугольника, в котором мог находиться абонент при регистрации на БС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BS_rectangle_coordinate(df_, CENTER_LAT, CENTER_LONG):\n",
    "    df = df_.copy()\n",
    "    lat_length = haversine_array(CENTER_LAT -.5, CENTER_LONG, CENTER_LAT + .5, CENTER_LONG)\n",
    "    long_length = haversine_array(CENTER_LAT, CENTER_LONG -.5, CENTER_LAT, CENTER_LONG + .5)\n",
    "    max_dist_mean = df['max_dist'].mean()\n",
    "\n",
    "    df['max_dist_correct'] = np.where(df['max_dist'] < 50, max_dist_mean, df['max_dist'])\n",
    "    df['max_dist_correct']\n",
    "    \n",
    "    for feature in ['long', 'lat']:\n",
    "        if (feature == 'long'):\n",
    "            coord_length = long_length\n",
    "        else:\n",
    "            coord_length = lat_length\n",
    "        df[feature + '_start'] = np.where(df['angle'] == 360,\n",
    "                                 df[feature] - df['max_dist_correct']/coord_length/1000, df[feature] + df['max_dist_correct'] * np.where(feature == 'long', \n",
    "                                                                                           np.sin(df['start_angle']),\n",
    "                                                                                           np.cos(df['start_angle'])\n",
    "                                                                                                 )/coord_length/1000)\n",
    "\n",
    "        df[feature + '_end'] = np.where(df['angle'] == 360,\n",
    "                               df[feature]+df['max_dist_correct']/coord_length/1000,\n",
    "                               df[feature] + df['max_dist_correct'] * np.where(feature == 'long', \n",
    "                                                                                           np.sin(df['end_angle']),\n",
    "                                                                                           np.cos(df['end_angle'])\n",
    "                                                                                                 )/coord_length/1000)\n",
    "                                                                                         \n",
    "        df[feature + '_min'] = df[[feature + '_start', feature + '_end', feature]].min(axis = 1)\n",
    "        df[feature + '_max'] = df[[feature + '_start', feature + '_end', feature]].max(axis = 1)\n",
    "        \n",
    "        df[feature] = (df[feature + '_max'] + df[feature + '_min'])/2\n",
    "        df.drop(columns = [feature + '_end', feature + '_start'], inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CreateTimeBeans` разбивает время на равные отрезки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "def CreateTimeBeans(df_, n_bins_ = 10):\n",
    "    df = df_.copy()\n",
    "    \n",
    "    dt_list = np.reshape(df.datetime.values.tolist(), (len(df.datetime.values.tolist()), 1))\n",
    "\n",
    "    enc = KBinsDiscretizer(n_bins=n_bins_, encode='ordinal', strategy='uniform')\n",
    "    dt_array_bins = enc.fit_transform(dt_list)\n",
    "\n",
    "    df['datetime_bin'] = dt_array_bins[:,0]\n",
    "    df['datetime_bin'] = df['datetime_bin'].astype('int')\n",
    "\n",
    "    return df, df['datetime_bin'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CreatePivotBase` создает промежуточный датафрейм, декартовое произведение интервалов времени и абонентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreatePivotBase(df):\n",
    "    \n",
    "    df_data_msisdn = pd.DataFrame(df['msisdn'].drop_duplicates()).sort_values('msisdn')\n",
    "    df_data_datetime = pd.DataFrame(df['datetime_bin'].drop_duplicates()).sort_values('datetime_bin')\n",
    "\n",
    "    df_data_msisdn['K'] = 1\n",
    "    df_data_datetime['K'] = 1\n",
    "    df_data_pivot_base = df_data_msisdn.merge(df_data_datetime, on = ['K']).reset_index().drop(columns = ['index', 'K'])\n",
    "    \n",
    "    return df_data_pivot_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AggData` создает промежуточный датафрейм, декартовое произведение интервалов времени и абонентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# аггрегация данных по интервалам\n",
    "def AggData(df):\n",
    "    #Создаем датафрейм в котором записаны часовые срезы расположения абонента и нумеруем в хронологическом порядке каждое состояние\n",
    "\n",
    "    df_data_agg = df.groupby(['msisdn',  'datetime_bin'])['long_min', 'long_max', 'lat_min', 'lat_max', 'long', 'lat'].mean().reset_index()\n",
    "    df_data_agg['datetime'] = df_data_agg['datetime_bin'] \n",
    "    df_data_agg = df_data_agg.sort_values(['msisdn', 'datetime_bin'])\n",
    "    df_data_agg['state'] = df_data_agg.groupby(['msisdn'])['msisdn'].cumcount()\n",
    "    return df_data_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AggData` создает промежуточный датафрейм, декартовое произведение интервалов времени и абонентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cдвигаю событие на пол часа и объединяю с оригинальными событиями\n",
    "def AddDataDelta(df_, delta = 30, n = 2):\n",
    "    df = df_.copy()\n",
    "    for i in range(0, n):\n",
    "        df_delta = df_.copy()\n",
    "        df_delta['datetime'] = df_delta['datetime'] - timedelta(seconds = (delta*60)) * (i + 1)\n",
    "        df = df.append(df_delta)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AggData` создает промежуточный датафрейм, декартовое произведение интервалов времени и абонентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearCombData(df_data_pivot_base, df_data_agg):\n",
    "    \n",
    "    df_data_pivot_base = df_data_pivot_base.merge(df_data_agg[['msisdn', 'datetime_bin', 'state']], on = ['msisdn', 'datetime_bin'], how = 'left')\n",
    "    df_data_pivot_base['state_previous'] = 1- df_data_pivot_base['state'].isna()*1\n",
    "    df_data_pivot_base['state_previous'] = df_data_pivot_base.groupby('msisdn')['state_previous'].cumsum() - 1\n",
    "    \n",
    "    df_data_pivot_base.drop(columns = ['state'], inplace = True)\n",
    "    df_data_pivot_base['state_next'] = df_data_pivot_base['state_previous'] + 1\n",
    "\n",
    "    for event in ['previous', 'next']:\n",
    "        df_data_pivot_base = df_data_pivot_base.merge(df_data_agg[['msisdn', 'long', 'long_max', 'long_min', 'lat', 'lat_max', 'lat_min', 'datetime_bin', 'state']].rename(columns = {'long':'long_' + event, 'lat':'lat_' + event, 'long_max':'long_max_' + event,\n",
    "                                                                             'lat_max':'lat_max_' + event,\n",
    "                                                                             'long_min':'long_min_' + event,\n",
    "                                                                             'lat_min':'lat_min_' + event,\n",
    "                                                                              'datetime_bin':'datetime_bin_' + event,\n",
    "                                                                              'state':'state_' + event}),\n",
    "                                                                    on = ['msisdn', 'state_' + event],\n",
    "                                                                    how = 'left')\n",
    "    for feature in ['long', 'long_max', 'long_min', 'lat', 'lat_max', 'lat_min']:\n",
    "    # расчитываю текущее событие для кажждого периода как линейную комбинацию окружающих реальных событий\n",
    "        df_data_pivot_base[feature] = np.where(df_data_pivot_base[feature+'_previous'].isna(),\n",
    "                                       df_data_pivot_base[feature+'_next'],\n",
    "                                       np.where(df_data_pivot_base[feature+'_next'].isna(),\n",
    "                                               df_data_pivot_base[feature+'_previous'],\n",
    "                                               df_data_pivot_base[feature+'_previous'] + \n",
    "                                                    (df_data_pivot_base['datetime_bin'] - df_data_pivot_base['datetime_bin_previous'])/\n",
    "                                                    (df_data_pivot_base['datetime_bin_next'] - df_data_pivot_base['datetime_bin_previous'])*\n",
    "                                                    (df_data_pivot_base[feature+'_next'] - df_data_pivot_base[feature+'_previous'])))              \n",
    "                                    \n",
    "\n",
    "    return df_data_pivot_base[['msisdn', 'datetime_bin', 'long', 'long_max', 'long_min', 'lat', 'lat_max', 'lat_min']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AggData` создает промежуточный датафрейм, декартовое произведение интервалов времени и абонентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CombData(df_data_pivot_base, df_data_agg):\n",
    "    \n",
    "    df_data_pivot_base = df_data_pivot_base.merge(df_data_agg, on = ['msisdn', 'datetime_bin'], how = 'left')\n",
    "\n",
    "    return df_data_pivot_base[['msisdn', 'datetime_bin', 'long', 'long_max', 'long_min', 'lat', 'lat_max', 'lat_min']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CreatePivot` Преобразует таблицу в массив с фичами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreatePivot(df_for_pivot):\n",
    "    df_pivot = df_for_pivot.pivot(index = 'msisdn', columns = 'datetime_bin', values = 'long')\n",
    "    df_pivot.columns = df_pivot.columns.astype('str') + '_' + 'long'\n",
    "\n",
    "    for feature in ['long_max', 'long_min', 'lat', 'lat_max', 'lat_min']:\n",
    "        df_agg_feature = df_for_pivot.pivot(index = 'msisdn', columns = 'datetime_bin', values = feature)\n",
    "        df_agg_feature.columns = df_agg_feature.columns.astype('str') + '_' + feature\n",
    "        df_pivot = pd.concat([df_pivot, df_agg_feature], axis = 1)\n",
    "\n",
    "    return df_pivot.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CreateMsisdnPairs` создает таблицу с парами абонентов, на которых мы будем обучать модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateMsisdnPairs(train_pairs, df, train_random_frac_, random_random_frac):\n",
    "    msisdn_pairs = pd.concat([train_pairs[[0, 1]].rename(columns = {0:'msisdn_x', 1:'msisdn_y'})\n",
    "                         ], axis = 0).drop_duplicates()\n",
    "    msisdn_pairs_dubli = pd.concat([train_pairs[[0, 1]].rename(columns = {0:'msisdn_x', 1:'msisdn_y'})\n",
    "                         ,train_pairs[[1, 0]].rename(columns = {1:'msisdn_x', 0:'msisdn_y'})\n",
    "                         ], axis = 0).drop_duplicates()\n",
    "    \n",
    "    msisdn_pairs['is_pair'] = 1\n",
    "    msisdn_pairs['K'] = 1\n",
    "    print('Sample pairs:', msisdn_pairs.shape[0])\n",
    "    msisdn_pairs_dubli['K'] = 1\n",
    "    \n",
    "    df_data_msisdn = pd.DataFrame(df['msisdn'].drop_duplicates()).sort_values('msisdn')\n",
    "    df_data_msisdn['K'] = 1\n",
    "\n",
    "    # любой номер из пары с другими номерами не создает пары\n",
    "    msisdn_pairs_part1 = df_data_msisdn[~df_data_msisdn['msisdn'].isin(msisdn_pairs_dubli['msisdn_x'])].rename(columns= {'msisdn':'msisdn_x'}).merge(msisdn_pairs_dubli[['K', 'msisdn_y']], on = ['K']).drop(columns = ['K'])\n",
    "    msisdn_pairs_part1.drop_duplicates(inplace = True)\n",
    "    msisdn_pairs_part1['is_pair'] = 0\n",
    "    \n",
    "    msisdn_pairs_part1 = msisdn_pairs_part1.sample(frac = train_random_frac_)\n",
    "    print('Pair Random pairs:', msisdn_pairs_part1.shape[0])\n",
    "    \n",
    "    '''\n",
    "    # пары, у которых оба номера не из списка\n",
    "    msisdn_pairs_part2 = df_data_msisdn[~df_data_msisdn['msisdn'].isin(msisdn_pairs_dubli['msisdn_x'])].rename(columns= {'msisdn':'msisdn_x'}).merge(df_data_msisdn[~df_data_msisdn['msisdn'].isin(msisdn_pairs_dubli['msisdn_x'])].rename(columns= {'msisdn':'msisdn_y'}), on = ['K']).drop(columns = ['K'])\n",
    "    print(msisdn_pairs_part2.columns)\n",
    "    msisdn_pairs_part2.drop_duplicates(inplace = True)\n",
    "    msisdn_pairs_part2['is_pair'] = 0\n",
    "    msisdn_pairs_part2 = msisdn_pairs_part2[msisdn_pairs_part2['msisdn_x'] < msisdn_pairs_part2['msisdn_y']]\n",
    "    msisdn_pairs_part2 = msisdn_pairs_part2.sample(frac = random_random_frac)\n",
    "    print('Random Random pairs:', msisdn_pairs_part2.shape[0])\n",
    "'''\n",
    "    # объедтняю пары и не пары\n",
    "    msisdn_pairs = pd.concat([msisdn_pairs, msisdn_pairs_part1\n",
    "   #                       , msisdn_pairs_part2\n",
    "                         ], axis = 0).drop(columns = ['K'])\n",
    "    \n",
    "    # перемешиваю первый и второй номер\n",
    "    msisdn_pairs_half_1 = msisdn_pairs.sample(frac = .5)\n",
    "    msisdn_pairs_half_2 = msisdn_pairs.append(msisdn_pairs_half_1).drop_duplicates(keep = False).rename(columns = {'msisdn_x':'msisdn_y', 'msisdn_y':'msisdn_x'})\n",
    "    msisdn_pairs = msisdn_pairs_half_1.append(msisdn_pairs_half_2)\n",
    "    print(msisdn_pairs.shape)\n",
    "    \n",
    "    return msisdn_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CreateAndProcessPivot` Обрабатываем pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateAndProcessPivot(msisdn_pairs, data_agg_pivot, bins_list, identifier,\n",
    "                          dist_ind = True,\n",
    "                          coord_ind = True,\n",
    "                          center_dist_ind = True,\n",
    "                          CENTER_LAT = 55.7522200,\n",
    "                          CENTER_LONG = 37.6155600):\n",
    "    \n",
    "    df_X = msisdn_pairs.merge(data_agg_pivot.rename(columns = {'msisdn':'msisdn_x'}), on = ['msisdn_x']).merge(data_agg_pivot.rename(columns = {'msisdn':'msisdn_y'}), on = ['msisdn_y'])\n",
    "    # считаю расстояние в каждом часе\n",
    "    columns_name_dist = list()\n",
    "    columns_name_intersect = list()\n",
    "    columns_name_lat_x = list()\n",
    "    columns_name_long_x = list()\n",
    "    columns_name_lat_y = list()\n",
    "    columns_name_long_y = list()\n",
    "    columns_name_center_dist_x = list()\n",
    "    columns_name_center_dist_y = list()\n",
    "    \n",
    "    columns_name = list()\n",
    "    columns_name_identifier = list()\n",
    "\n",
    "    lat_length = haversine_array(CENTER_LAT -.5, CENTER_LONG, CENTER_LAT + .5, CENTER_LONG)\n",
    "    long_length = haversine_array(CENTER_LAT, CENTER_LONG -.5, CENTER_LAT, CENTER_LONG + .5)\n",
    "\n",
    "    for i in bins_list:\n",
    "        str_i = str(int(i))\n",
    "        columns_name_dist.append(str_i+\"_dist\")\n",
    "        columns_name_intersect.append(str_i+\"_intersect\")\n",
    "        columns_name_lat_x.append(str_i+\"_lat_x\")\n",
    "        columns_name_long_x.append(str_i+\"_long_x\")\n",
    "        columns_name_lat_y.append(str_i+\"_lat_y\")\n",
    "        columns_name_long_y.append(str_i+\"_long_y\")\n",
    "        columns_name_center_dist_x.append(str_i+\"_center_dist_x\")\n",
    "        columns_name_center_dist_y.append(str_i+\"_center_dist_y\")\n",
    "\n",
    "        lat_diff = (df_X[str_i+\"_lat_x\"].values - df_X[str_i+\"_lat_y\"].values)*lat_length\n",
    "        long_diff = (df_X[str_i+\"_long_x\"].values - df_X[str_i+\"_long_y\"].values)*long_length\n",
    "        dist = np.sqrt(lat_diff**2 + long_diff**2)\n",
    "        df_X[str_i+\"_dist\"] = dist\n",
    "        df_X[str_i+'_intersect'] = ((df_X[str_i+'_lat_max_x'] >= df_X[str_i+'_lat_min_y']) &\n",
    "                              (df_X[str_i+'_lat_max_y'] >= df_X[str_i+'_lat_min_x']) &\n",
    "                              (df_X[str_i+'_long_max_x'] >= df_X[str_i+'_long_min_y']) &\n",
    "                              (df_X[str_i+'_long_max_y'] >= df_X[str_i+'_long_min_x'])) * 1\n",
    "        center_x_lat_diff = (df_X[str_i+\"_lat_x\"].values - CENTER_LAT)*lat_length\n",
    "        center_y_lat_diff = (df_X[str_i+\"_lat_y\"].values - CENTER_LAT)*lat_length\n",
    "        \n",
    "        center_x_long_diff = (df_X[str_i+\"_long_x\"].values - CENTER_LONG)*long_length\n",
    "        center_y_long_diff = (df_X[str_i+\"_long_y\"].values - CENTER_LONG)*long_length\n",
    "\n",
    "        df_X[str_i+\"_center_dist_x\"] = np.sqrt(center_x_lat_diff**2 + center_x_long_diff**2)\n",
    "        df_X[str_i+\"_center_dist_y\"] = np.sqrt(center_y_lat_diff**2 + center_y_long_diff**2)\n",
    "    \n",
    "    # считаю среднее расстояние    \n",
    "    df_X['dist_mean'] = df_X[columns_name_dist].mean(axis = 1)\n",
    "    df_X['intersect_mean'] = df_X[columns_name_intersect].mean(axis = 1)\n",
    "    df_X['intersect_count'] = df_X[columns_name_dist].count(axis = 1)/len(bins_list)\n",
    "    df_X['center_dist_x_mean'] = df_X[columns_name_center_dist_x].mean(axis = 1)\n",
    "    df_X['center_dist_y_mean'] = df_X[columns_name_center_dist_y].mean(axis = 1)\n",
    "    \n",
    "    if(dist_ind):\n",
    "        columns_name = [*columns_name, *columns_name_dist]\n",
    "    \n",
    "    if(coord_ind):\n",
    "        columns_name = [*columns_name, *columns_name_lat_x, *columns_name_lat_y, *columns_name_long_x, *columns_name_long_y]\n",
    "\n",
    "    if(center_dist_ind):\n",
    "        columns_name = [*columns_name, *columns_name_center_dist_x, *columns_name_center_dist_y]\n",
    "    \n",
    "    columns_name = [*columns_name, \n",
    "                    *['dist_mean', 'intersect_mean', 'intersect_count', 'center_dist_x_mean', 'center_dist_y_mean']]\n",
    "        \n",
    "    columns_name = [*columns_name, *['is_pair', 'msisdn_x', 'msisdn_y']]\n",
    "    df_X = df_X[columns_name].set_index(['is_pair', 'msisdn_x', 'msisdn_y'])\n",
    "    df_X.columns = df_X.columns + '_' + identifier\n",
    "    \n",
    "    print(df_X.shape)\n",
    "    \n",
    "    return df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessPhoneFeaturesPivot(df_msisdn_device, msisdn_pairs, df):\n",
    "    \n",
    "    msisdn_imei_count = df[~df['imei'].isna()].groupby(['msisdn', 'imei'])['lac'].count().reset_index().sort_values('lac', ascending = False)\n",
    "    pairs_with_same_imei = msisdn_imei_count.merge(msisdn_imei_count, on = ['imei'])\n",
    "    pairs_with_same_imei = pairs_with_same_imei[['msisdn_x', 'msisdn_y']]\n",
    "    pairs_with_same_imei = pairs_with_same_imei.drop_duplicates()\n",
    "    pairs_with_same_imei = pairs_with_same_imei[pairs_with_same_imei['msisdn_x'] != pairs_with_same_imei['msisdn_y']]\n",
    "    pairs_with_same_imei['same_imei'] = 1\n",
    "\n",
    "    df_X = msisdn_pairs.merge(df_msisdn_device.rename(columns = {'msisdn':'msisdn_x'}), on = ['msisdn_x']).merge(df_msisdn_device.rename(columns = {'msisdn':'msisdn_y'}), on = ['msisdn_y'])\n",
    "\n",
    "    df_X = df_X.merge(pairs_with_same_imei, on = ['msisdn_x', 'msisdn_y'], how = 'left')\n",
    "    df_X['same_imei'] = df_X['same_imei'].fillna(0)\n",
    "    df_X.set_index(['is_pair', 'msisdn_x', 'msisdn_y'], inplace = True)\n",
    "    \n",
    "    return df_X[['imei_x', 'type_x', 'vendor_x', 'platform_x', 'imei_y', 'type_y', 'vendor_y', 'platform_y', 'same_imei']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
